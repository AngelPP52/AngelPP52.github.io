(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{529:function(t,s,a){t.exports=a.p+"assets/img/2.1_MapReduce_Process.c6fc829a.png"},530:function(t,s,a){t.exports=a.p+"assets/img/2.2_MapReduce_Process.b73d1ecb.png"},531:function(t,s,a){t.exports=a.p+"assets/img/2.3_MapReduce_Process_Cache.25017346.png"},532:function(t,s,a){t.exports=a.p+"assets/img/2.4_CountMinSketch.5cf6742c.png"},533:function(t,s,a){t.exports=a.p+"assets/img/2.5_DataFrame.612334ec.png"},534:function(t,s,a){t.exports=a.p+"assets/img/2.6_DataFrame.96f3f2bf.png"},535:function(t,s,a){t.exports=a.p+"assets/img/2.7_DataFrame.38425179.png"},562:function(t,s,a){"use strict";a.r(s);var e=a(4),n=Object(e.a)({},(function(){var t=this,s=t.$createElement,e=t._self._c||s;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h2",{attrs:{id:"_1-背景"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1-背景"}},[t._v("#")]),t._v(" 1. 背景")]),t._v(" "),e("p",[t._v("前不久我在周会上分享了"),e("a",{attrs:{href:"https://drive.google.com/file/d/1fftN6yrv_4kyLeLBclI6XZtc9y8NRWx1/view",target:"_blank",rel:"noopener noreferrer"}},[t._v("浅谈海量数据"),e("OutboundLink")],1),t._v("，主要简单介绍了"),e("strong",[t._v("MapReduce")]),t._v("的原理及其应用("),e("strong",[t._v("Page Rank")]),t._v(")。而这篇文章是基于上次的分享，再来浅谈周会分享中提到的"),e("strong",[t._v("Top K问题")]),t._v("(也有一个类似的问题叫"),e("strong",[t._v("The Heavy Hitters Problem")]),t._v("，主要是寻找出现频数较高的数值)。Top K问题在我们的日常生活中也是处处可见，如购物平台的推荐商品，搜索热词，检测较大流量的TCP连接(检测DDoS)等等。本文主要通过"),e("strong",[t._v("Top K")]),t._v("问题来阐述"),e("strong",[t._v("MapReduce")]),t._v("在大数据处理中的应用，详细描述了在单台机器上，多台机器上，低的QPS，高的QPS中MapReduce如何工作，最后简单介绍了近似算法来解决Top K问题。")]),t._v(" "),e("h2",{attrs:{id:"_2-阐述top-k问题"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-阐述top-k问题"}},[t._v("#")]),t._v(" 2. 阐述Top K问题")]),t._v(" "),e("p",[t._v("我们先来看看一个简化了的Top K问题：输入是一个长度为"),e("strong",[t._v("n")]),t._v("的数组"),e("strong",[t._v("A")]),t._v("以及一个参数"),e("strong",[t._v("k")]),t._v("，"),e("strong",[t._v("n")]),t._v("是一个非常大的数，如几百万，几千万，而"),e("strong",[t._v("k")]),t._v("是一个相对较小的数，如10，100或1000。目标就是找到在数组"),e("strong",[t._v("A")]),t._v("里出现频数至少是"),e("strong",[t._v("n/k")]),t._v("的数值。")]),t._v(" "),e("p",[t._v("在阐述如何解决Top K问题之前，先让我们来看一个读书时老师会问到的问题(题目来源于LeetCode)：")]),t._v(" "),e("p",[e("a",{attrs:{href:"https://leetcode-cn.com/problems/top-k-frequent-elements/",target:"_blank",rel:"noopener noreferrer"}},[t._v("(Top K Frequent Elements) Given a non-empty array of integers, return the k most frequent elements."),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("接下来我会以这个问题为例进行Top K问题的介绍。")]),t._v(" "),e("h3",{attrs:{id:"_2-1-top-k-on-single-node"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-top-k-on-single-node"}},[t._v("#")]),t._v(" 2.1 Top K on Single Node")]),t._v(" "),e("p",[t._v("在"),e("strong",[t._v("单结点")]),t._v("(一台机器)上解决Top K问题（或者在单台机器上解决问题），通常用到的数据结构是"),e("strong",[t._v("HashMap")]),t._v("和"),e("strong",[t._v("Heap")]),t._v("(小顶堆), 时间复杂度是"),e("strong",[t._v("O(n + n * lgk) = O(n * lgk)")]),t._v(", 空间复杂度是**O(|n| + k), |n| **是不重复数值的个数。")]),t._v(" "),e("ul",[e("li",[e("strong",[t._v("HashMap")]),t._v("主要是记录每个元素出现的频数")]),t._v(" "),e("li",[t._v("把HashMap中记录的数值放进小顶堆(大小为K)，当堆还没满时，直接把数值放进去就行")]),t._v(" "),e("li",[t._v("当堆满时，比较堆顶的数值和准备放进堆的数值，如果准备放进堆的数值的频数比堆顶数值频数大，把堆顶数值踢掉，放进新的数值，反之不做任何操作。")]),t._v(" "),e("li",[t._v("最后堆里就存储了Top K的数值(出现频数的Top K数值)。")]),t._v(" "),e("li",[t._v("以下以python为例简单写下此过程，而关于堆的实现，可以参考"),e("a",{attrs:{href:"https://algs4.cs.princeton.edu/home/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Algorithms, 4th Edition"),e("OutboundLink")],1),t._v(" (非常棒的介绍算法的书籍) 。")])]),t._v(" "),e("div",{staticClass:"language-python line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" Queue "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" PriorityQueue\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Solution")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("object")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("topKFrequent")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nums"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n        :type nums: List[int]\n        :type k: int\n        :rtype: List[int]\n        """')]),t._v("\n        m "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" num "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" nums"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            m"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("num"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" m"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n        \n        q "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" PriorityQueue"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" num "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" m"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            q"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("put"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("m"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("num"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" q"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("qsize"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" k"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                q"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n        ans "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" q"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("qsize"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            ans"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("q"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" ans\n")])]),t._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[t._v("1")]),e("br"),e("span",{staticClass:"line-number"},[t._v("2")]),e("br"),e("span",{staticClass:"line-number"},[t._v("3")]),e("br"),e("span",{staticClass:"line-number"},[t._v("4")]),e("br"),e("span",{staticClass:"line-number"},[t._v("5")]),e("br"),e("span",{staticClass:"line-number"},[t._v("6")]),e("br"),e("span",{staticClass:"line-number"},[t._v("7")]),e("br"),e("span",{staticClass:"line-number"},[t._v("8")]),e("br"),e("span",{staticClass:"line-number"},[t._v("9")]),e("br"),e("span",{staticClass:"line-number"},[t._v("10")]),e("br"),e("span",{staticClass:"line-number"},[t._v("11")]),e("br"),e("span",{staticClass:"line-number"},[t._v("12")]),e("br"),e("span",{staticClass:"line-number"},[t._v("13")]),e("br"),e("span",{staticClass:"line-number"},[t._v("14")]),e("br"),e("span",{staticClass:"line-number"},[t._v("15")]),e("br"),e("span",{staticClass:"line-number"},[t._v("16")]),e("br"),e("span",{staticClass:"line-number"},[t._v("17")]),e("br"),e("span",{staticClass:"line-number"},[t._v("18")]),e("br"),e("span",{staticClass:"line-number"},[t._v("19")]),e("br"),e("span",{staticClass:"line-number"},[t._v("20")]),e("br"),e("span",{staticClass:"line-number"},[t._v("21")]),e("br"),e("span",{staticClass:"line-number"},[t._v("22")]),e("br"),e("span",{staticClass:"line-number"},[t._v("23")]),e("br"),e("span",{staticClass:"line-number"},[t._v("24")]),e("br")])]),e("h3",{attrs:{id:"_2-2-top-k-on-multiple-node"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-top-k-on-multiple-node"}},[t._v("#")]),t._v(" 2.2 Top K on Multiple Node")]),t._v(" "),e("p",[t._v("但是当数据量非常大的时候，单机处理Top K是否恰当。比如有"),e("strong",[t._v("一组100T的文件，文件内容是10亿")]),t._v("用户当天的搜索记录，求当天搜索的热搜词。如果继续用单机处理这个问题，主要会出现两个问题：文件太大内存不够，处理速度非常慢。这时候，我们可以考虑用多台机器进行"),e("strong",[t._v("MapReduce")]),t._v("处理，关于MapReduce可以参考之前的分享"),e("a",{attrs:{href:"https://drive.google.com/file/d/1fftN6yrv_4kyLeLBclI6XZtc9y8NRWx1/view?usp=sharing",target:"_blank",rel:"noopener noreferrer"}},[t._v("浅谈海量数据"),e("OutboundLink")],1),t._v("。")]),t._v(" "),e("ul",[e("li",[t._v("可以每次从100T的文件中每次读取1G的文件，进行搜索词拆分并进行哈希处理，发送到相对应的机器进行Top K处理。")]),t._v(" "),e("li",[t._v("把各个机器的Top K搜索词进行合并，并取其中的Top K搜索词。( "),e("strong",[t._v("list of Top K {top k1, top k2, ...} => merge to get final top k")]),t._v(" )")])]),t._v(" "),e("p",[e("img",{attrs:{src:a(529),alt:""}}),t._v("\n图2.1 MapReduce 流程")]),t._v(" "),e("h3",{attrs:{id:"_2-3-realtime-top-k-with-low-qps"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-realtime-top-k-with-low-qps"}},[t._v("#")]),t._v(" 2.3 Realtime Top K with low QPS")]),t._v(" "),e("p",[t._v("之前讨论的Top K问题都是对于"),e("strong",[t._v("静态数据")]),t._v("来说的。现在又有另外一个场景，有"),e("strong",[t._v("实时数据")]),t._v("的流入，我们应该如何解决Top K问题呢？")]),t._v(" "),e("p",[t._v("想法一：")]),t._v(" "),e("ul",[e("li",[t._v("当有新数据流入时，把数据写入磁盘中")]),t._v(" "),e("li",[t._v("当有请求Top K时，基于磁盘上的数据求解Top K")]),t._v(" "),e("li")]),t._v(" "),e("p",[t._v("这样做主要有两个问题：")]),t._v(" "),e("ul",[e("li",[t._v("重复计算，每次都要基于磁盘中的数据重新进行Top K求解")]),t._v(" "),e("li",[t._v("计算速度太慢了")])]),t._v(" "),e("p",[t._v("想法二：")]),t._v(" "),e("ul",[e("li",[t._v("当有新数据流入时，把数据存储在HashMap")]),t._v(" "),e("li",[t._v("当HashMap更新了，相对应更新Priority Queue")]),t._v(" "),e("li",[t._v("从Priority Queue得到Top K")])]),t._v(" "),e("p",[t._v("这样做主要有两个问题：")]),t._v(" "),e("ul",[e("li",[t._v("OOM (内存不够)")]),t._v(" "),e("li",[t._v("当机器挂掉时候会丢失当前的数据")])]),t._v(" "),e("p",[t._v("那么为什么会导致内存不够呢？"),e("strong",[t._v("HashMap")]),t._v(" ? 还是"),e("strong",[t._v("Priority Queue")]),t._v(" ?")]),t._v(" "),e("p",[t._v("我觉得是HashMap会导致内存不够，因为Priority Queue只是会保存K个key-value数值对，而"),e("strong",[t._v("HashMap则是不断地新增数值，最终导致内存不够用")]),t._v("。")]),t._v(" "),e("p",[t._v("现在，我们可以尝试用"),e("strong",[t._v("数据库(如MySQL)去替代HashMap")]),t._v("，这样我们可以把单词的频数存储在数据库中，如下：")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[t._v("id")]),t._v(" "),e("th",{staticStyle:{"text-align":"center"}},[t._v("word")]),t._v(" "),e("th",{staticStyle:{"text-align":"right"}},[t._v("count")])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("1")]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[t._v("computer")]),t._v(" "),e("td",{staticStyle:{"text-align":"right"}},[t._v("10")])]),t._v(" "),e("tr",[e("td",[t._v("2")]),t._v(" "),e("td",{staticStyle:{"text-align":"center"}},[t._v("science")]),t._v(" "),e("td",{staticStyle:{"text-align":"right"}},[t._v("9")])])])]),t._v(" "),e("p",[t._v("这时候如果还用Priority Queue去保存Top K的值就会出现问题。如果用数据库替代HashMap，新的单词可以跟以前一样，直接和小顶堆的根值比较即可；但"),e("strong",[t._v("如果这个单词已经存在于小顶堆里面，我们需要更新该单词在小顶堆中的值，而不是让该单词直接和小顶堆的根值进行比较")]),t._v("。")]),t._v(" "),e("p",[t._v("这时候，我们可以考虑用TreeMap去代替"),e("strong",[t._v("Priority Queue")]),t._v("。"),e("strong",[t._v("TreeMap")]),t._v("是有序的key-value集合，通过红黑树来实现，支持查找和删除操作，可以在O(logn)时间内做查找，插入和删除等操作。这样对于已经存在于TreeMap的单词，我们可以更新该单词对应的频数值。")]),t._v(" "),e("h3",{attrs:{id:"_2-4-realtime-top-k-with-high-qps"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-realtime-top-k-with-high-qps"}},[t._v("#")]),t._v(" 2.4 Realtime Top K with high QPS")]),t._v(" "),e("p",[t._v("但是当数据流有"),e("strong",[t._v("很高的QPS")]),t._v("，这时候我们应该如何去解决这个问题呢？QPS很高，意味着数据库不能实时地做出反应，因为读写的频率太高了，这导致了"),e("strong",[t._v("很高的延迟性(high latency)")]),t._v("。")]),t._v(" "),e("p",[t._v("这时候我们可以考虑2.2提到的多节点处理Top K的方法去解决这个问题。但是当某个单词非常热门，这会导致某个节点的 写QPS 会非常高，同样又会导致**2.2很高的延迟性(high latency)**2.2。流程如下：")]),t._v(" "),e("p",[e("img",{attrs:{src:a(530),alt:""}}),t._v("\n图2.2 获取Top K流程")]),t._v(" "),e("ul",[e("li",[t._v("新的数据发送给Slave 1进行处理")]),t._v(" "),e("li",[t._v("Slave 1会把新的数据存储在数据库上")]),t._v(" "),e("li",[t._v("数据库的更新会触发TreeMap的更新，此时TreeMap会先进入block状态，然后对新数据进行更新")]),t._v(" "),e("li",[t._v("此时Master接收到Top K的请求")]),t._v(" "),e("li",[t._v("Master Node会去请求Slave 1，返回Top K")]),t._v(" "),e("li",[t._v("Slave 1就会去TreeMap请求Top K")]),t._v(" "),e("li",[t._v("因为数据流"),e("strong",[t._v("有非常高的QPS")]),t._v("，数据库不停的进行读写操作，相对应TreeMap不停地进行"),e("strong",[t._v("Block和Update操作")]),t._v("，此时TreeMap还"),e("strong",[t._v("处于Block")]),t._v("状态，于是返回Wait消息给Slave 1")]),t._v(" "),e("li",[t._v("Slave 1返回Wait的消息给Mater Node，此时Master Node并不能实时得到Top K的数据，"),e("strong",[t._v("导致很高的延迟性")])])]),t._v(" "),e("p",[t._v("就像是算法里面的时间复杂度和空间复杂度，通过"),e("strong",[t._v("增加空间复杂度来降低时间复杂度")]),t._v("，比如用并查集解决朋友圈问题。对于上面阐述的高延迟性问题，同样可以"),e("strong",[t._v("牺牲一点精确性来减少")]),t._v("延迟性。这时候我们可以利用"),e("strong",[t._v("缓存")]),t._v("来解决高延迟性的问题。流程如下：")]),t._v(" "),e("p",[e("img",{attrs:{src:a(531),alt:""}}),t._v("\n图2.3 获取Top K流程(cache)")]),t._v(" "),e("ul",[e("li",[t._v("新的数据发送给Slave 1进行处理")]),t._v(" "),e("li",[t._v("Slave 1会把新的数据缓存起来")]),t._v(" "),e("li",[t._v("每隔一段时间，如每隔10秒缓存会把缓存的数据存储在数据库上")]),t._v(" "),e("li",[t._v("数据库的更新会触发TreeMap的更新，此时TreeMap会先进入block状态，然后对新数据进行更新")]),t._v(" "),e("li",[t._v("此时Master接收到Top K的请求")]),t._v(" "),e("li",[t._v("Master Node会去请求Slave 1，返回Top K")]),t._v(" "),e("li",[t._v("Slave 1就会去TreeMap请求Top K")]),t._v(" "),e("li",[t._v("此时因为数据的更新并不是特别频繁，TreeMap并没有一直处于block状态，此时TreeMap返回Top K数值")]),t._v(" "),e("li",[t._v("Slave 1返回Top K数值给Mater Node")])]),t._v(" "),e("h3",{attrs:{id:"_2-5-approximate-top-k"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-approximate-top-k"}},[t._v("#")]),t._v(" 2.5 Approximate Top K")]),t._v(" "),e("p",[t._v("现在有一个问题，对于高频词问题，肯定会有很多单词出现的频率非常低，这样"),e("strong",[t._v("低频词会占据磁盘很大部分的容量")]),t._v("。就像2.4提到的用缓存解决高QPS的Top K问题，适当"),e("strong",[t._v("降低精确性来提高空间的使用率")]),t._v("。接下来我们来看看"),e("strong",[t._v("Count-Min Sketch")]),t._v("和"),e("strong",[t._v("Lossy Counting")]),t._v("如何解决"),e("strong",[t._v("Top K")]),t._v("问题，这两个近似算法都是优化了存储单词出现频数的方法 [1][2]，计算Top K那部分依旧是用小顶堆或Tree Map来解决。")]),t._v(" "),e("h3",{attrs:{id:"_2-5-1-count-min-sketch"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-1-count-min-sketch"}},[t._v("#")]),t._v(" 2.5.1 Count-Min Sketch")]),t._v(" "),e("p",[e("strong",[t._v("Count-Min Sketch")]),t._v("类似于"),e("strong",[t._v("Bloom Filter")]),t._v("，都是用多个哈希函数去解决冲突问题 [1][2][3]。假设我们有"),e("strong",[t._v("d个哈希函数")]),t._v("，一个数组T(d行，m列)，对于数据流中的每个数据，用d个哈希函数计算得到"),e("strong",[t._v("d个哈希值")]),t._v("，把其d个哈希值对"),e("strong",[t._v("m进行取模运算")]),t._v("，并对其所在数组的位置的值"),e("strong",[t._v("加一")]),t._v("，即T[hash_func][hash_value] + 1。当我们去搜索某个单词的频数时，通过d个哈希函数我们可以得到"),e("strong",[t._v("d个哈希值")]),t._v("，相对应可以找到d个哈希值对应其所在的数组的值，这时我们"),e("strong",[t._v("选择数值最小的数值")]),t._v("作为该单词的"),e("strong",[t._v("频数")]),t._v(" [4]。")]),t._v(" "),e("p",[e("img",{attrs:{src:a(532),alt:""}}),t._v("\n图2.4 Count-Min Sketch [4]")]),t._v(" "),e("p",[e("strong",[t._v("Count-Min Sketch")]),t._v("的优点就是可以"),e("strong",[t._v("节省很多空间")]),t._v("；缺点是对于低频词，有可能通过计算把该单词变成高频词。")]),t._v(" "),e("h3",{attrs:{id:"_2-5-2-losssy-counting"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-2-losssy-counting"}},[t._v("#")]),t._v(" 2.5.2 Losssy Counting")]),t._v(" "),e("p",[e("strong",[t._v("Lossy Counting")]),t._v("是另一个用来解决数据流中的Top K问题的近似算法，对于数据流中的数据，如果"),e("strong",[t._v("其出现频数超过某个自定义的数值")]),t._v("，就把该数值记录下来 [3]。首先我们先创建一个HashMap，用来存储单词的频数(key是单词，value是其频数)，然后建立"),e("strong",[t._v("data frame(如数组)")]),t._v("，如下：")]),t._v(" "),e("p",[e("img",{attrs:{src:a(533),alt:""}}),t._v("\n图2.5 Data Frame [3]")]),t._v(" "),e("p",[t._v("从数据流中读取数值，并把数据放进"),e("strong",[t._v("data frame")]),t._v("中，统计其"),e("strong",[t._v("频数f")]),t._v("，并将"),e("strong",[t._v("其频数减一")]),t._v("(我觉得这是非常非常非常聪明的一种做法)，如下：")]),t._v(" "),e("p",[e("img",{attrs:{src:a(534),alt:""}}),t._v("\n图2.6 计算Data Frame中数值的频数 [3]")]),t._v(" "),e("p",[t._v("把计算得到的频数放进"),e("strong",[t._v("HashMap")]),t._v("中，并把HashMap中"),e("strong",[t._v("频数为0")]),t._v("的key-value数值对"),e("strong",[t._v("删除")]),t._v("(这就是为什么计算频数时需要将其减一的原因)。重复以上步骤，以此来统计单词出现的频数，如下：")]),t._v(" "),e("p",[e("img",{attrs:{src:a(535),alt:""}}),t._v("\n图2.7 计算Data Frame中数值的频数 [3]")]),t._v(" "),e("p",[t._v("这个方法背后的思想主要是即使在"),e("strong",[t._v("每个data frame")]),t._v("中计算频数时都要减一，但是高频词出现的频率就很高，这就说明"),e("strong",[t._v("在每一个data frame中高频词在HashMap中被删除的几率会很低")]),t._v("。当我们不断从数据流中读取数据，"),e("strong",[t._v("低频词在HashMap中记录的频数会越来越低，直至到零时就会从HashMap中删除掉[3][5]")]),t._v("。")]),t._v(" "),e("h2",{attrs:{id:"_3-总结"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-总结"}},[t._v("#")]),t._v(" 3. 总结")]),t._v(" "),e("p",[e("strong",[t._v("Top K")]),t._v("问题在我们的日常生活中是处处可见，如购物平台的推荐商品，搜索热词，检测较大流量的TCP连接(检测DDoS)等等。在单台机器上，解决"),e("strong",[t._v("Top K")]),t._v("问题，通常需要堆的帮助选择出现频数最高的K个数值。但是当数据越来越大的时候，单台机器通常内存不足以处理如此庞大的数据，这时候就需要用到多台机器对数据进行"),e("strong",[t._v("Map和Reduce合并处理")]),t._v("。但是实际生活中，数据是流动的，不断增加的，当机器的"),e("strong",[t._v("QPS比较低")]),t._v("的时候，这时候可以用"),e("strong",[t._v("数据库存")]),t._v("储记录每个数值出现的频数，每当有新的数据时，更新数据库，并把此数值的频数和小顶堆的根值比较即可，这时候，我们可以考虑用"),e("strong",[t._v("TreeMap")]),t._v("去代替Priority Queue，因为"),e("strong",[t._v("TreeMap是有序的key-value集合")]),t._v("，通过红黑树来实现，支持查找和删除操作，可以在O(logn)时间内做查找，插入和删除等操作。当机器的QPS比较高的时候，因为读写频率比较高，此时如果不停的访问数据库，很容易造成很高的延迟性，这时候可以"),e("strong",[t._v("缓存")]),t._v("一部分数据来解决高延迟性的问题。此外，如果可以接受结果会有一些偏差，我们也可以使用一些"),e("strong",[t._v("近似算法来解决数据流的Top K问题")]),t._v("，如Count-Min Sketch和Losssy Counting。")]),t._v(" "),e("h2",{attrs:{id:"references"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#references"}},[t._v("#")]),t._v(" References")]),t._v(" "),e("p",[e("strong",[t._v("[1]")]),t._v(" T. Roughgarden, G. Valiant (Mar. 30, 2016). Stanford University CS168: The Modern Algorithmic Toolbox Lecture #2: Approximate Heavy Hitters and the Count-Min Sketch. Retrieved from http://theory.stanford.edu/~tim/s17/l/l2.pdf.")]),t._v(" "),e("p",[e("strong",[t._v("[2]")]),t._v(" Vazirani, Rao. University of California, Berkeley, CS270: Lecture 15 Streaming Algorithms: Frequent Items. Retrieved from https://people.eecs.berkeley.edu/~satishr/cs270/sp11/rough-notes/Streaming-two.pdf.")]),t._v(" "),e("p",[e("strong",[t._v("[3]")]),t._v(" M. Vogiatzis (July 18, 2015). Frequency Counting Algorithms over Data Streams. Retrieved from https://micvog.com/2015/07/18/frequency-counting-algorithms-over-data-streams/.")]),t._v(" "),e("p",[e("strong",[t._v("[4]")]),t._v(" Z. Jiang (Nov. 13, 2017), Top K Frequent Items Algorithms. Retrieved from https://zpjiang.me/2017/11/13/top-k-elementes-system-design/.")]),t._v(" "),e("p",[e("strong",[t._v("[5]")]),t._v(" M. Hadjieleftheriou, S. Muthukrishnan, R. Berinde, P. Indyk, M. Strauss. Finding Frequent Items in Data Streams. Retrieved from http://archive.dimacs.rutgers.edu/Workshops/WGUnifyingTheory/Slides/cormode.pdf.")])])}),[],!1,null,null,null);s.default=n.exports}}]);